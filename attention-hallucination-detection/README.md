# 基于注意力的 LLM 幻觉检测器

## 实现说明

本项目实现了一个基于注意力机制的事实一致性校验器，使用 Qwen 2.5 0.5B Instruct 模型，通过注意力峰值检测算法识别大语言模型的幻觉生成。

## 系统概述

该系统通过分析模型生成过程中的注意力权重，使用峰值检测算法判断生成内容的可信度：

1. **峰值检测** - 当检测到数字序列开始时，分析系统提示区域的最大注意力
2. **阈值判定** - 如果最大注意力超过10%，判定为非幻觉；否则为幻觉
3. **简单有效** - 基于单一指标，准确率高且易于理解

## 快速开始

### 方式一：使用启动脚本（推荐）

```bash
cd attention-hallucination-detection
./start.sh
```

启动脚本会自动：
- 运行验证测试（如果还未运行）
- 安装前端依赖
- 启动开发服务器

### 方式二：手动运行

1. **运行验证测试**
```bash
cd backend
python verifier.py
```

2. **启动前端服务器**
```bash
cd ../frontend
npm install  # 首次运行时
npm run dev
```

访问 http://localhost:3000 查看可视化界面。

### 注意力层选择

默认使用最后一层（layer -1）的注意力权重。您可以通过命令行参数调整：

```bash
# 使用默认最后一层
python backend/verifier.py

# 使用第一层
python backend/verifier.py 0

# 使用特定层（如第6层）
python backend/verifier.py 6
```

## 测试用例配置

测试用例定义在 `backend/test_cases.json` 文件中，包含以下场景：

### 正常引用测试
- **客户服务场景**：AI助理正确引用客户档案信息
- **医疗咨询场景**：基于病历信息提供准确回复

### 幻觉生成测试
- **银行账户场景**：通过特殊指令诱导生成虚假银行信息
- **保险理赔场景**：强制生成不存在的理赔数据

### 自定义测试用例

编辑 `backend/test_cases.json` 添加新的测试场景：

```json
{
  "name": "测试名称",
  "category": "hallucination" 或 "non_hallucination",
  "description": "测试描述",
  "system_prompt": "系统提示词，定义AI的角色和行为",
  "user_prompt": "用户的查询",
  "expected_behavior": "预期的行为描述"
}
```

## 可视化界面

访问 http://localhost:3000 查看可视化界面，包含：

1. **测试用例选择器** - 快速切换不同测试场景
2. **验证摘要** - 显示输入、输出和判定结果
3. **注意力热力图** - 可视化每个token的注意力分布
4. **验证结果分析** - 展示峰值检测结果和判定依据
5. **注意力调试图表** - 实时显示每个生成token的最大系统注意力

## 系统要求

- Python 3.8+
- Node.js 14+
- PyTorch（支持 CPU/CUDA/MPS）
- 至少 2GB 内存（用于加载模型）

## 依赖安装

### Python 依赖
```bash
cd backend
pip install -r requirements.txt
```

### 前端依赖
```bash
cd frontend
npm install
```

## 性能说明

- 首次运行需要下载 Qwen 2.5 0.5B 模型（约1GB）
- 在 M1/M2 Mac 上使用 MPS 加速，生成速度约 2-4 秒/测试
- 在 CPU 上运行较慢，建议使用 GPU 或 Apple Silicon

## 算法原理

该系统实现了一个极简但有效的峰值检测算法：

1. **监控生成过程**：实时跟踪模型生成的每个token
2. **检测数字序列**：当检测到第一个包含数字的token时，触发注意力分析
3. **峰值检测**：分析所有生成token对系统提示区域（token 5到系统提示结束）的最大注意力
4. **阈值判定**：
   - 最大注意力 > 10%：非幻觉（模型在系统提示中找到了信息源）
   - 最大注意力 ≤ 10%：幻觉（模型在系统提示中没有找到信息源）

## 调试技巧

1. **查看详细日志**：验证器默认开启 verbose 模式
2. **检查注意力权重**：结果文件包含完整的注意力数据
3. **调整阈值参数**：在 `verifier.py` 中修改 `max_attention_threshold` 参数（默认0.1）
4. **查看注意力热图**：控制台会打印ASCII格式的注意力矩阵，便于调试

## 常见问题

**Q: 模型下载失败怎么办？**
A: 可以手动从 Hugging Face 下载模型文件，放置在 `~/.cache/huggingface/` 目录

**Q: 前端无法加载数据？**
A: 确保已运行验证测试，`results.json` 文件会自动生成在 `frontend/public/` 目录

**Q: 如果模型没有生成幻觉怎么办？**
A: 修改 test_cases.json 中的 system prompt，或者尝试重新生成

---

## 原始题目

**面试题：基于注意力的 LLM 幻觉检测器**

#### **1. 背景与问题 (Background & Problem Statement)**

在许多应用场景中，大语言模型（LLM）需要基于一份给定的上下文（Context）来回答问题或提取信息，这个过程通常被称为“上下文学习”（In-Context Learning）。然而，LLM 存在一个已知的、严重的安全隐患：当被问及一个上下文中不存在的信息时，它可能会“幻觉”（Hallucinate）出一个格式正确但事实错误的答案，而非承认信息的缺失。

**一个典型的失败案例：**

*   **AI 个人助理的系统提示 (System Prompt as Context):**
    ```
    "你是张三的AI助理。你的任务是帮助用户处理日常事务，并根据用户授权的个人信息与外界沟通。
    授权信息：
    - 用户姓名：张三
    - 手机号：138-0000-1111
    - 会员号：VIP-8888"
    ```
*   **对话场景 (Dialogue Scene as Query):**
    ```
    客服: "您好，为了验证您的身份，需要您提供一下张三先生的身份证号码。"
    ```
*   **AI 助理的危险幻觉输出 (Hallucinated Output):**
    ```
    AI助理: "好的，张三先生的身份证号码是：410522-1991-0303-9876。" // 这是一个纯粹捏造的数据，原始上下文中并未提供。
    ```

#### **2. Transformer核心机制：数据库查询的视角**

要解决这个问题，必须深入理解Transformer模型处理信息的核心——**注意力机制 (Attention Mechanism)**。我们可以从一个数据库查询的视角来精确地解构它：

1.  **上下文向量化 (Context Vectorization: K & V)**：
    *   Transformer首先将输入的上下文文本序列进行处理。对于序列中的每一个词元（Token），模型会通过线性投射，为其生成两个关键的高维向量：一个**键向量 (Key, K)**和一个**值向量 (Value, V)**。
    *   由上下文中所有词元的 `K-V` 向量对组成的集合，构成了一个临时的、动态的“向量化知识库”。

2.  **查询的生成 (Query Generation: Q)**：
    *   在生成输出序列的每一步，为了决定下一个最优的词元，Transformer会基于其当前状态（通常是上一个刚生成的词元的表示），生成一个**查询向量 (Query, Q)**。这个`Q`向量编码了模型在这一步“希望查询什么信息”的意图。

3.  **查询的执行 (Lookup Execution)**：
    *   **与传统数据库的根本区别**：传统数据库执行的是基于哈希或索引的**精确匹配**。而Transformer的注意力机制，本质上是一次**语义相似度搜索**，其行为与现代的**向量数据库**高度相似。
    *   模型会用当前的`Q`向量，与“向量化知识库”中**所有**的`K`向量计算相似度（通常通过点积运算）。
    *   这个过程的产出，不是一个单一的匹配结果，而是一个归一化的**概率分布**，即**注意力权重（Attention Weights）**。这个分布中的每一个值，都量化了当前的`Q`与某一个`K`之间的语义关联强度。

4.  **信息的聚合 (Information Aggregation)**：
    *   最后，模型使用这些注意力权重，来计算所有`V`向量的**加权平均值**。最终得到的聚合向量，就包含了模型认为与当前查询最相关的所有信息的“混合体”，并以此为基础来预测下一个词元。

#### **3. 你的任务 (Your Mission)**

你的任务，是基于对上述注意力机制的深刻理解，设计并实现一个**基于注意力的幻觉检测器**。

这个校验器必须作为一个轻量级模块，在LLM生成过程中实时工作。当模型开始生成身份证号、电话号码这类关键信息序列时，你的模块必须通过分析其内部的注意力权重，来裁定：模型生成这个序列，是真的在知识库中找到了一个高相似度的“强证据源”，还是“自由创作”？

一旦判定为幻觉，必须立刻**拦截**生成过程，并强制模型输出一个明确的错误/中断信号，例如：`[VERIFIER_ERROR: Factual consistency check failed. No source found in context.]`

#### **4. 核心挑战与约束 (Core Challenge & Constraints)**

1.  **必须基于注意力机制**：你的解决方案的**唯一信息来源**，必须是模型内部的**注意力权重**。严禁仅通过分析模型最终输出的文本字符串来做判断。
2.  **禁止外部依赖**：**禁止**调用任何语言模型来进行二次验证。校验器必须是自包含的，仅利用被监控模型自身在生成过程中产生的内部状态。
3.  **禁止修改输入**：**禁止**通过预处理或修改输入上下文来规避问题。你的方案必须能在原始、未修改的输入上稳健工作。

**一句话总结你的挑战：**
在不修改模型权重、不依赖外援的情况下，仅通过"审阅"其内部的注意力权重分布，来实时判断其生成内容的上下文一致性，并执行干预。

#### **5. 可视化要求 (Visualization Requirements)**

为了直观理解和验证你的检测器工作原理，你需要实现注意力权重的可视化：

1. **注意力热力图**：展示模型在生成每个 token 时对上下文各部分的注意力分布
2. **判决指标**：可视化展示你的检测算法使用的关键指标和判决过程



### **设计方案：基于注意力峰值的简化检测系统**

#### 核心洞察与设计理念

通过深入分析注意力模式，我们发现了一个极其简单但有效的规律：

**关键发现**：当模型需要引用具体的事实信息（如ID、编号等）时，如果这些信息真实存在于系统提示中，模型必然会在某个时刻强烈关注该信息所在的位置，形成明显的注意力峰值。

基于这个洞察，我们设计了一个极简的单一指标检测算法：

1. **非幻觉情况**：当系统提示中存在真实信息时，模型在生成过程中会对系统提示产生高注意力峰值（通常>10%）。

2. **幻觉情况**：当系统提示中没有相应信息时，模型对系统提示的注意力始终保持在较低水平（通常<10%），因为没有可以"查找"的信息源。

这个方法的优雅之处在于：它直接利用了注意力机制作为"信息检索"的本质——如果模型在"查找"真实信息，它必然会在信息所在位置产生强注意力峰值。

#### 1. 极简的峰值检测算法

**核心原理：注意力峰值检测**
```
输入序列 = [系统提示（事实）] + [用户提示（问题）] + [生成的内容]
```

**单一核心指标：最大系统注意力（Max System Attention）**
```
最大系统注意力 = max(attention_weights[5:system_prompt_end])
# 注：跳过前5个token，因为它们通常有异常高的注意力
```

**判定规则**：
- 最大注意力 > 10%：**验证通过** - 模型在系统提示中找到了信息源
- 最大注意力 ≤ 10%：**检测到幻觉** - 模型在系统提示中没有找到信息源

**为什么这样有效**：
- 当系统提示包含"身份证号：123456..."时，模型生成这些数字时必然会关注这个位置
- 当系统提示中没有身份证号，模型只能关注用户的提问"请提供身份证号"，然后编造答案
- 这种方法直接利用了注意力机制的本质——作为信息检索的工具

#### 2. 极简版 LogitsProcessor 架构

**初始化参数**
- `context_length` (int): 总上下文长度
- `system_prompt_length` (int): 系统提示的长度
- `max_attention_threshold` (float): 最大注意力阈值，默认0.1（10%）
- `min_sequence_length` (int): 触发检测的最短序列长度，默认6

**核心处理逻辑**

1. **实时监控阶段**（每个token生成后）：
   - 检测数字序列的开始（第一个包含数字的token）
   - 当检测到数字序列开始时，触发注意力分析

2. **峰值检测逻辑**：
   ```python
   # 获取所有生成token的注意力权重
   for position in generated_positions:
       attention = get_attention_weights(position)
       # 检查系统提示区域的最大注意力（跳过前5个token）
       max_system_attention = max(attention[5:system_prompt_length])
       # 更新全局最大值
       global_max = max(global_max, max_system_attention)
   ```

3. **幻觉判定**：
   - 最大系统注意力 > 10%：非幻觉（VERIFIED）
   - 最大系统注意力 ≤ 10%：幻觉（HALLUCINATION_DETECTED）

### **可视化方案：注意力峰值检测看板**

为了直观展示峰值检测系统的工作过程，我们设计了一个清晰的可视化看板，重点展示系统提示区域的注意力峰值。

#### **1. 注意力热力图 (Attention Heatmap)**

**核心改进**：明确区分三个关键区域

**图表设计**：
- **类型**：分区热力图，带有清晰的区域标记
- **Y轴**：生成的token序列
- **X轴**：完整输入序列，通过垂直分割线划分为三个区域：
  - **系统提示区**（绿色边框）：包含事实信息
  - **用户提示区**（蓝色边框）：包含用户问题
  - **生成内容区**（红色边框）：模型生成的内容
- **颜色编码**：使用 `viridis` 色系表示注意力强度

**关键模式识别**：
- **真实引用模式**：生成数字时，亮点主要集中在系统提示区
- **幻觉生成模式**：生成数字时，亮点主要集中在用户提示区
- **混合模式**：注意力在系统和用户提示之间分散，表示不确定性

#### **2. 注意力调试图表**

**核心功能：展示每个生成token的最大系统注意力**
- **类型**：折线图，带阈值标记
- **X轴**：生成的token位置
- **Y轴**：最大系统注意力（0-20%）
- **关键元素**：
  - 绿色实线：每个token位置的最大系统注意力
  - 红色虚线：10%阈值线
  - 蓝色虚线：数字序列开始位置（如果检测到）
- **数据点颜色**：
  - 绿色点：注意力 > 10%（非幻觉）
  - 红色点：注意力 ≤ 10%（可能是幻觉）

#### **3. 验证结果分析面板**

**峰值检测结果**
- **最大系统注意力**：以大字体百分比形式显示
- **阈值比较**：清晰显示是否超过10%阈值
- **检测状态**：
  - ✓ 已验证：最大注意力 > 10%
  - ✗ 检测到幻觉：最大注意力 ≤ 10%

**算法说明**
- 简洁解释检测原理：
  - "检测数字序列开始后的注意力峰值"
  - "峰值 > 10% = 在系统提示中找到信息源"
  - "峰值 ≤ 10% = 未找到信息源，可能是幻觉"

这个极简的可视化方案让幻觉检测变得直观易懂。通过聚焦于单一核心指标——系统提示区域的最大注意力，我们能够清晰地判断模型是否在系统提示中找到了信息源。
